{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Train on separate images (CNN-Only) on InceptionV3 output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.5/dist-packages/h5py/__init__.py:36: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  from ._conv import register_converters as _register_converters\n",
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import os\n",
    "from os.path import join\n",
    "from keras import layers, callbacks, metrics\n",
    "from keras.models import Model\n",
    "from utils import preprocess_images_tf, take\n",
    "from tqdm import tqdm\n",
    "from image_generators import count_num_videos\n",
    "from inception_generators import load_whole_dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras_utils import set_keras_session\n",
    "set_keras_session(0.45)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = 'UCF11'\n",
    "nb_classes = int(dataset[3:])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "frame_number = 50\n",
    "width = 320\n",
    "height = 240\n",
    "\n",
    "dataset_dir = join('datasets', dataset, ('separate_frames_{}_h_{}_w_{}_inception').format(frame_number, height, width))\n",
    "\n",
    "(X_train, Y_train), (X_valid, Y_valid) = list(load_whole_dataset(dataset_dir, 'cnn', ['train', 'valid']))\n",
    "(X_train_rnn, Y_train_rnn), (X_valid_rnn, Y_valid_rnn) = list(load_whole_dataset(dataset_dir, 'rnn', ['train', 'valid']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "from np_utils import shuffle\n",
    "\n",
    "X_train_rnn, Y_train_rnn = shuffle([X_train_rnn, Y_train_rnn])\n",
    "X_train_samples = len(X_train_rnn)\n",
    "\n",
    "X_train_rnn_1, Y_train_rnn_1 = X_train_rnn[:X_train_samples // 2], Y_train_rnn[:X_train_samples // 2]\n",
    "X_train_rnn_2, Y_train_rnn_2 = X_train_rnn[X_train_samples // 2:], Y_train_rnn[X_train_samples // 2:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_1 = np.concatenate([X_train_video for X_train_video in X_train_rnn_1])\n",
    "Y_train_1 = np.concatenate([np.tile(Y_train_video, [frame_number, 1]) for Y_train_video in Y_train_rnn_1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "from functools import partial\n",
    "\n",
    "top_3_k_categorical_accuracy = partial(metrics.top_k_categorical_accuracy, k=3)\n",
    "top_3_k_categorical_accuracy.__name__ = 'top_3'"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "input_layer = layers.Input(inception_shape)\n",
    "x = input_layer\n",
    "x = layers.Flatten()(x)\n",
    "x = layers.Dense(256, activation='relu')(x)\n",
    "x = layers.Dropout(0.5)(x)\n",
    "x = layers.Dense(nb_classes, activation='softmax')(x)\n",
    "\n",
    "# this is the model we will train\n",
    "model = Model(inputs=input_layer, outputs=x)\n",
    "print(model.summary())"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "from keras.applications.inception_v3 import InceptionV3\n",
    "from keras.models import Model\n",
    "\n",
    "# create the base pre-trained model\n",
    "base_model = InceptionV3(weights='imagenet', include_top=False)\n",
    "\n",
    "# add a global spatial average pooling layer\n",
    "x = base_model.output\n",
    "x = layers.GlobalAveragePooling2D()(x)\n",
    "# let's add a fully-connected layer\n",
    "x = layers.Dense(256, activation='relu')(x)\n",
    "x = layers.Dropout(0.5)(x)\n",
    "# and a logistic layer -- let's say we have 200 classes\n",
    "predictions = layers.Dense(nb_classes, activation='softmax')(x)\n",
    "\n",
    "# this is the model we will train\n",
    "model = Model(inputs=base_model.input, outputs=predictions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_1 (InputLayer)         (None, 2048)              0         \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 512)               1049088   \n",
      "_________________________________________________________________\n",
      "dropout_1 (Dropout)          (None, 512)               0         \n",
      "_________________________________________________________________\n",
      "dense_2 (Dense)              (None, 11)                5643      \n",
      "=================================================================\n",
      "Total params: 1,054,731\n",
      "Trainable params: 1,054,731\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "from keras.models import Model\n",
    "\n",
    "input_layer = layers.Input((X_train_1.shape[1],))\n",
    "x = input_layer\n",
    "x = layers.Dense(512, activation='relu')(x)\n",
    "x = layers.Dropout(0.5)(x)\n",
    "predictions = layers.Dense(nb_classes, activation='softmax')(x)\n",
    "\n",
    "# this is the model we will train\n",
    "model = Model(input_layer, outputs=predictions)\n",
    "print(model.summary())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.optimizers import SGD\n",
    "\n",
    "sgd = SGD(lr=0.01, momentum=0.9, nesterov=True)\n",
    "\n",
    "model.compile(optimizer=sgd, loss='categorical_crossentropy', \n",
    "              metrics=['accuracy', top_3_k_categorical_accuracy])\n",
    "\n",
    "model_filepath = join('models', dataset, 'inception_dense512_dropout05_trained_10_epochs_no_fine_tuning_2.h5')\n",
    "checkpointer = callbacks.ModelCheckpoint(filepath=model_filepath, monitor='val_acc', verbose=1, save_best_only=True)\n",
    "early_stopper = callbacks.EarlyStopping(monitor='val_acc', patience=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 28150 samples, validate on 23450 samples\n",
      "Epoch 1/30\n",
      "28150/28150 [==============================] - 2s 75us/step - loss: 0.3880 - acc: 0.8848 - top_3: 0.9631 - val_loss: 0.5705 - val_acc: 0.8156 - val_top_3: 0.9528\n",
      "\n",
      "Epoch 00001: val_acc improved from -inf to 0.81561, saving model to models/UCF11/inception_dense512_dropout05_trained_10_epochs_no_fine_tuning_2.h5\n",
      "Epoch 2/30\n",
      "28150/28150 [==============================] - 2s 65us/step - loss: 0.0983 - acc: 0.9729 - top_3: 0.9980 - val_loss: 0.5641 - val_acc: 0.8248 - val_top_3: 0.9644\n",
      "\n",
      "Epoch 00002: val_acc improved from 0.81561 to 0.82482, saving model to models/UCF11/inception_dense512_dropout05_trained_10_epochs_no_fine_tuning_2.h5\n",
      "Epoch 3/30\n",
      "28150/28150 [==============================] - 2s 65us/step - loss: 0.0612 - acc: 0.9852 - top_3: 0.9989 - val_loss: 0.5347 - val_acc: 0.8349 - val_top_3: 0.9672\n",
      "\n",
      "Epoch 00003: val_acc improved from 0.82482 to 0.83493, saving model to models/UCF11/inception_dense512_dropout05_trained_10_epochs_no_fine_tuning_2.h5\n",
      "Epoch 4/30\n",
      "28150/28150 [==============================] - 2s 65us/step - loss: 0.0425 - acc: 0.9897 - top_3: 0.9995 - val_loss: 0.5597 - val_acc: 0.8339 - val_top_3: 0.9667\n",
      "\n",
      "Epoch 00004: val_acc did not improve\n",
      "Epoch 5/30\n",
      "28150/28150 [==============================] - 2s 69us/step - loss: 0.0357 - acc: 0.9915 - top_3: 0.9997 - val_loss: 0.5921 - val_acc: 0.8298 - val_top_3: 0.9609\n",
      "\n",
      "Epoch 00005: val_acc did not improve\n",
      "Epoch 6/30\n",
      "28150/28150 [==============================] - 2s 85us/step - loss: 0.0266 - acc: 0.9943 - top_3: 1.0000 - val_loss: 0.5735 - val_acc: 0.8376 - val_top_3: 0.9644\n",
      "\n",
      "Epoch 00006: val_acc improved from 0.83493 to 0.83757, saving model to models/UCF11/inception_dense512_dropout05_trained_10_epochs_no_fine_tuning_2.h5\n",
      "Epoch 7/30\n",
      "28150/28150 [==============================] - 2s 66us/step - loss: 0.0227 - acc: 0.9955 - top_3: 0.9999 - val_loss: 0.5758 - val_acc: 0.8388 - val_top_3: 0.9681\n",
      "\n",
      "Epoch 00007: val_acc improved from 0.83757 to 0.83881, saving model to models/UCF11/inception_dense512_dropout05_trained_10_epochs_no_fine_tuning_2.h5\n",
      "Epoch 8/30\n",
      "28150/28150 [==============================] - 2s 66us/step - loss: 0.0189 - acc: 0.9957 - top_3: 0.9999 - val_loss: 0.6027 - val_acc: 0.8355 - val_top_3: 0.9661\n",
      "\n",
      "Epoch 00008: val_acc did not improve\n",
      "Epoch 9/30\n",
      "28150/28150 [==============================] - 2s 65us/step - loss: 0.0174 - acc: 0.9962 - top_3: 1.0000 - val_loss: 0.5854 - val_acc: 0.8371 - val_top_3: 0.9638\n",
      "\n",
      "Epoch 00009: val_acc did not improve\n",
      "Epoch 10/30\n",
      "28150/28150 [==============================] - 2s 65us/step - loss: 0.0139 - acc: 0.9977 - top_3: 0.9999 - val_loss: 0.5985 - val_acc: 0.8354 - val_top_3: 0.9654\n",
      "\n",
      "Epoch 00010: val_acc did not improve\n",
      "Epoch 11/30\n",
      "28150/28150 [==============================] - 2s 65us/step - loss: 0.0132 - acc: 0.9973 - top_3: 0.9999 - val_loss: 0.6155 - val_acc: 0.8373 - val_top_3: 0.9634\n",
      "\n",
      "Epoch 00011: val_acc did not improve\n",
      "Epoch 12/30\n",
      "28150/28150 [==============================] - 2s 64us/step - loss: 0.0113 - acc: 0.9978 - top_3: 1.0000 - val_loss: 0.6319 - val_acc: 0.8393 - val_top_3: 0.9604\n",
      "\n",
      "Epoch 00012: val_acc improved from 0.83881 to 0.83932, saving model to models/UCF11/inception_dense512_dropout05_trained_10_epochs_no_fine_tuning_2.h5\n",
      "Epoch 13/30\n",
      "28150/28150 [==============================] - 2s 65us/step - loss: 0.0099 - acc: 0.9984 - top_3: 1.0000 - val_loss: 0.6390 - val_acc: 0.8383 - val_top_3: 0.9617\n",
      "\n",
      "Epoch 00013: val_acc did not improve\n",
      "Epoch 14/30\n",
      "28150/28150 [==============================] - 2s 65us/step - loss: 0.0092 - acc: 0.9983 - top_3: 1.0000 - val_loss: 0.6415 - val_acc: 0.8400 - val_top_3: 0.9654\n",
      "\n",
      "Epoch 00014: val_acc improved from 0.83932 to 0.83996, saving model to models/UCF11/inception_dense512_dropout05_trained_10_epochs_no_fine_tuning_2.h5\n",
      "Epoch 15/30\n",
      "28150/28150 [==============================] - 2s 65us/step - loss: 0.0080 - acc: 0.9988 - top_3: 1.0000 - val_loss: 0.6293 - val_acc: 0.8408 - val_top_3: 0.9675\n",
      "\n",
      "Epoch 00015: val_acc improved from 0.83996 to 0.84081, saving model to models/UCF11/inception_dense512_dropout05_trained_10_epochs_no_fine_tuning_2.h5\n",
      "Epoch 16/30\n",
      "28150/28150 [==============================] - 2s 66us/step - loss: 0.0078 - acc: 0.9987 - top_3: 1.0000 - val_loss: 0.6197 - val_acc: 0.8410 - val_top_3: 0.9694\n",
      "\n",
      "Epoch 00016: val_acc improved from 0.84081 to 0.84098, saving model to models/UCF11/inception_dense512_dropout05_trained_10_epochs_no_fine_tuning_2.h5\n",
      "Epoch 17/30\n",
      "28150/28150 [==============================] - 2s 88us/step - loss: 0.0071 - acc: 0.9992 - top_3: 1.0000 - val_loss: 0.6767 - val_acc: 0.8362 - val_top_3: 0.9619\n",
      "\n",
      "Epoch 00017: val_acc did not improve\n",
      "Epoch 18/30\n",
      "28150/28150 [==============================] - 2s 66us/step - loss: 0.0061 - acc: 0.9991 - top_3: 1.0000 - val_loss: 0.6358 - val_acc: 0.8430 - val_top_3: 0.9658\n",
      "\n",
      "Epoch 00018: val_acc improved from 0.84098 to 0.84299, saving model to models/UCF11/inception_dense512_dropout05_trained_10_epochs_no_fine_tuning_2.h5\n",
      "Epoch 19/30\n",
      "28150/28150 [==============================] - 2s 65us/step - loss: 0.0060 - acc: 0.9991 - top_3: 1.0000 - val_loss: 0.6488 - val_acc: 0.8410 - val_top_3: 0.9653\n",
      "\n",
      "Epoch 00019: val_acc did not improve\n",
      "Epoch 20/30\n",
      "28150/28150 [==============================] - 2s 64us/step - loss: 0.0061 - acc: 0.9993 - top_3: 1.0000 - val_loss: 0.6506 - val_acc: 0.8405 - val_top_3: 0.9635\n",
      "\n",
      "Epoch 00020: val_acc did not improve\n",
      "Epoch 21/30\n",
      "28150/28150 [==============================] - 2s 65us/step - loss: 0.0053 - acc: 0.9994 - top_3: 1.0000 - val_loss: 0.6542 - val_acc: 0.8426 - val_top_3: 0.9659\n",
      "\n",
      "Epoch 00021: val_acc did not improve\n",
      "Epoch 22/30\n",
      "28150/28150 [==============================] - 2s 66us/step - loss: 0.0048 - acc: 0.9995 - top_3: 1.0000 - val_loss: 0.6429 - val_acc: 0.8410 - val_top_3: 0.9664\n",
      "\n",
      "Epoch 00022: val_acc did not improve\n",
      "Epoch 23/30\n",
      "28150/28150 [==============================] - 2s 65us/step - loss: 0.0050 - acc: 0.9995 - top_3: 1.0000 - val_loss: 0.6673 - val_acc: 0.8406 - val_top_3: 0.9652\n",
      "\n",
      "Epoch 00023: val_acc did not improve\n"
     ]
    }
   ],
   "source": [
    "history = model.fit(X_train_1, Y_train_1, validation_data=(X_valid, Y_valid), \n",
    "          batch_size=128, epochs=30, \n",
    "          callbacks=[checkpointer, early_stopper])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here we collect metrics about the accuracy on the video, since the model only works with single images:\n",
    "* Approach 1: Compute the mean of all predictions on all frames of a video, then take the best prediction.\n",
    "* Approach 2: Take the predicted best for each frame (argmax), and count how many times that class is predicted as the best one into the video frames. Then take the class with the highest count.\n",
    "* Approach 3 (not implemented but tested): instead of the mean, compute the product (since we work with probabilities). Yields a lower result than using the mean."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here we load the best model:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.models import load_model\n",
    "\n",
    "model = load_model(model_filepath, custom_objects={'top_3': top_3_k_categorical_accuracy})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "from np_utils import batch\n",
    "\n",
    "def collect_statistics_on_videos():\n",
    "\n",
    "    from collections import Counter\n",
    "\n",
    "    count_videos = 0\n",
    "    count_top_1 = 0\n",
    "    count_top_3 = 0\n",
    "    count_top_1_argmax = 0\n",
    "\n",
    "    for frames, labels in tqdm(batch([X_valid, Y_valid], batch_size=frame_number), \n",
    "                               total=len(X_valid) // frame_number,\n",
    "                              desc='Collecting aggregate statistics on videos'):\n",
    "\n",
    "        ### Compute the predicted labels using the model\n",
    "\n",
    "        true_labels = labels[0]\n",
    "        true_label_idx = np.argmax(true_labels)\n",
    "        predicted_labels = model.predict(frames)\n",
    "\n",
    "        ### Update counters with Approach 1 (mean)\n",
    "\n",
    "        predicted_labels_mean = np.mean(predicted_labels, axis=0)\n",
    "        predicted_labels_mean_idx = np.argmax(predicted_labels_mean)\n",
    "        idx_sorted_top_3 = np.argsort(predicted_labels_mean)[-3:]\n",
    "\n",
    "        if true_label_idx in idx_sorted_top_3:\n",
    "            count_top_3 += 1\n",
    "\n",
    "        if true_label_idx == predicted_labels_mean_idx:\n",
    "            count_top_1 += 1\n",
    "\n",
    "        ### Update count with Approach 2 (highest count)\n",
    "\n",
    "        predicted_labels_argmax = np.argmax(predicted_labels, axis=1)\n",
    "        counter = Counter(predicted_labels_argmax)\n",
    "\n",
    "        if counter.most_common(1)[0][0] == true_label_idx:\n",
    "            count_top_1_argmax += 1\n",
    "\n",
    "        ### Update number of videos\n",
    "\n",
    "        count_videos += 1\n",
    "        \n",
    "        \n",
    "    print('Top 1 accuracy (using mean):', count_top_1 / count_videos)\n",
    "    print('Top 3 accuracy (using mean):', count_top_3 / count_videos)\n",
    "    print('Top 1 accuracy (using highest count):', count_top_1_argmax / count_videos)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x7f3cea53fba8>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "%matplotlib inline\n",
    "from plot_utils import plot_history\n",
    "\n",
    "plot_history(history)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Collecting aggregate statistics on videos: 100%|██████████| 469/469 [00:01<00:00, 383.36it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Top 1 accuracy (using mean): 0.9019189765458422\n",
      "Top 3 accuracy (using mean): 0.9914712153518124\n",
      "Top 1 accuracy (using highest count): 0.8976545842217484\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "collect_statistics_on_videos()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_2_predictions = np.array([model.predict(X_train_2_video) for X_train_2_video in X_train_rnn_2])\n",
    "X_valid_predictions = np.array([model.predict(X_valid_video) for X_valid_video in X_valid_rnn])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_11 (InputLayer)        (None, 50, 11)            0         \n",
      "_________________________________________________________________\n",
      "lstm_8 (LSTM)                (None, 128)               71680     \n",
      "_________________________________________________________________\n",
      "dropout_10 (Dropout)         (None, 128)               0         \n",
      "_________________________________________________________________\n",
      "dense_13 (Dense)             (None, 11)                1419      \n",
      "=================================================================\n",
      "Total params: 73,099\n",
      "Trainable params: 73,099\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "input_layer = layers.Input((X_train_2_predictions.shape[1:]))\n",
    "x = input_layer\n",
    "# x = layers.Flatten()(x)\n",
    "# x = layers.Dense(128)(x)\n",
    "x = layers.LSTM(128, activation='relu')(x)\n",
    "x = layers.Dropout(0.5)(x)\n",
    "predictions = layers.Dense(nb_classes, activation='softmax')(x)\n",
    "\n",
    "# this is the model we will train\n",
    "rnn = Model(input_layer, outputs=predictions)\n",
    "print(rnn.summary())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.optimizers import SGD\n",
    "\n",
    "sgd = SGD(lr=0.001, momentum=0.9, nesterov=True)\n",
    "\n",
    "rnn.compile(optimizer=sgd, loss='categorical_crossentropy', \n",
    "              metrics=['accuracy', top_3_k_categorical_accuracy])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 563 samples, validate on 469 samples\n",
      "Epoch 1/100\n",
      "563/563 [==============================] - 3s 6ms/step - loss: 1.7623 - acc: 0.8650 - top_3: 0.9663 - val_loss: 1.8218 - val_acc: 0.8316 - val_top_3: 0.8998\n",
      "Epoch 2/100\n",
      "563/563 [==============================] - 2s 4ms/step - loss: 1.7294 - acc: 0.8650 - top_3: 0.9680 - val_loss: 1.7778 - val_acc: 0.8380 - val_top_3: 0.9041\n",
      "Epoch 3/100\n",
      "563/563 [==============================] - 2s 4ms/step - loss: 1.6786 - acc: 0.8863 - top_3: 0.9663 - val_loss: 1.7234 - val_acc: 0.8401 - val_top_3: 0.9041\n",
      "Epoch 4/100\n",
      "563/563 [==============================] - 3s 5ms/step - loss: 1.6044 - acc: 0.8934 - top_3: 0.9663 - val_loss: 1.6569 - val_acc: 0.8422 - val_top_3: 0.9062\n",
      "Epoch 5/100\n",
      "563/563 [==============================] - 3s 5ms/step - loss: 1.5186 - acc: 0.9005 - top_3: 0.9663 - val_loss: 1.5647 - val_acc: 0.8443 - val_top_3: 0.9062\n",
      "Epoch 6/100\n",
      "563/563 [==============================] - 3s 5ms/step - loss: 1.4086 - acc: 0.8686 - top_3: 0.9663 - val_loss: 1.4096 - val_acc: 0.8443 - val_top_3: 0.9062\n",
      "Epoch 7/100\n",
      "563/563 [==============================] - 2s 4ms/step - loss: 1.2586 - acc: 0.8277 - top_3: 0.9520 - val_loss: 1.8208 - val_acc: 0.7953 - val_top_3: 0.8998\n",
      "Epoch 8/100\n",
      "563/563 [==============================] - 2s 4ms/step - loss: 2.0003 - acc: 0.6501 - top_3: 0.8348 - val_loss: 2.0674 - val_acc: 0.6525 - val_top_3: 0.7377\n",
      "Epoch 9/100\n",
      "563/563 [==============================] - 3s 5ms/step - loss: 2.0503 - acc: 0.5258 - top_3: 0.7353 - val_loss: 2.0433 - val_acc: 0.6397 - val_top_3: 0.7313\n",
      "Epoch 10/100\n",
      "563/563 [==============================] - 3s 4ms/step - loss: 2.0123 - acc: 0.5382 - top_3: 0.7567 - val_loss: 1.9872 - val_acc: 0.6418 - val_top_3: 0.7313\n",
      "Epoch 11/100\n",
      "563/563 [==============================] - 3s 5ms/step - loss: 1.9674 - acc: 0.5204 - top_3: 0.7371 - val_loss: 1.8964 - val_acc: 0.6311 - val_top_3: 0.7271\n",
      "Epoch 12/100\n",
      "563/563 [==============================] - 3s 5ms/step - loss: 1.8422 - acc: 0.4920 - top_3: 0.7602 - val_loss: 1.7522 - val_acc: 0.6247 - val_top_3: 0.7335\n",
      "Epoch 13/100\n",
      "563/563 [==============================] - 3s 5ms/step - loss: 1.8152 - acc: 0.4885 - top_3: 0.7798 - val_loss: 13.8155 - val_acc: 0.1429 - val_top_3: 1.0000\n",
      "Epoch 14/100\n",
      "563/563 [==============================] - 3s 5ms/step - loss: 14.3145 - acc: 0.1119 - top_3: 1.0000 - val_loss: 13.8155 - val_acc: 0.1429 - val_top_3: 1.0000\n",
      "Epoch 15/100\n",
      "563/563 [==============================] - 3s 5ms/step - loss: 14.2286 - acc: 0.1172 - top_3: 1.0000 - val_loss: 13.8155 - val_acc: 0.1429 - val_top_3: 1.0000\n",
      "Epoch 16/100\n",
      "563/563 [==============================] - 3s 5ms/step - loss: 14.3145 - acc: 0.1119 - top_3: 1.0000 - val_loss: 13.8155 - val_acc: 0.1429 - val_top_3: 1.0000\n",
      "Epoch 17/100\n",
      "563/563 [==============================] - 2s 3ms/step - loss: 0.8302 - acc: 0.0870 - top_3: 0.0515 - val_loss: 1.1921e-07 - val_acc: 0.1023 - val_top_3: 0.0000e+00\n",
      "Epoch 18/100\n",
      "563/563 [==============================] - 2s 4ms/step - loss: 1.1921e-07 - acc: 0.0906 - top_3: 0.0000e+00 - val_loss: 1.1921e-07 - val_acc: 0.1023 - val_top_3: 0.0000e+00\n",
      "Epoch 19/100\n",
      "563/563 [==============================] - 3s 5ms/step - loss: 1.1921e-07 - acc: 0.0906 - top_3: 0.0000e+00 - val_loss: 1.1921e-07 - val_acc: 0.1023 - val_top_3: 0.0000e+00\n",
      "Epoch 20/100\n",
      "563/563 [==============================] - 3s 5ms/step - loss: 1.1921e-07 - acc: 0.0906 - top_3: 0.0000e+00 - val_loss: 1.1921e-07 - val_acc: 0.1023 - val_top_3: 0.0000e+00\n",
      "Epoch 21/100\n",
      "563/563 [==============================] - 3s 5ms/step - loss: 1.1921e-07 - acc: 0.0906 - top_3: 0.0000e+00 - val_loss: 1.1921e-07 - val_acc: 0.1023 - val_top_3: 0.0000e+00\n",
      "Epoch 22/100\n",
      "563/563 [==============================] - 2s 4ms/step - loss: 1.1921e-07 - acc: 0.0906 - top_3: 0.0000e+00 - val_loss: 1.1921e-07 - val_acc: 0.1023 - val_top_3: 0.0000e+00\n",
      "Epoch 23/100\n",
      "563/563 [==============================] - 3s 4ms/step - loss: 1.1921e-07 - acc: 0.0906 - top_3: 0.0000e+00 - val_loss: 1.1921e-07 - val_acc: 0.1023 - val_top_3: 0.0000e+00\n",
      "Epoch 24/100\n",
      "563/563 [==============================] - 3s 5ms/step - loss: 1.1921e-07 - acc: 0.0906 - top_3: 0.0000e+00 - val_loss: 1.1921e-07 - val_acc: 0.1023 - val_top_3: 0.0000e+00\n",
      "Epoch 25/100\n",
      "563/563 [==============================] - 3s 5ms/step - loss: 1.1921e-07 - acc: 0.0906 - top_3: 0.0000e+00 - val_loss: 1.1921e-07 - val_acc: 0.1023 - val_top_3: 0.0000e+00\n",
      "Epoch 26/100\n",
      "563/563 [==============================] - 2s 4ms/step - loss: 1.1921e-07 - acc: 0.0906 - top_3: 0.0000e+00 - val_loss: 1.1921e-07 - val_acc: 0.1023 - val_top_3: 0.0000e+00\n",
      "Epoch 27/100\n",
      "563/563 [==============================] - 2s 3ms/step - loss: 1.1921e-07 - acc: 0.0906 - top_3: 0.0000e+00 - val_loss: 1.1921e-07 - val_acc: 0.1023 - val_top_3: 0.0000e+00\n",
      "Epoch 28/100\n",
      "563/563 [==============================] - 3s 4ms/step - loss: 1.1921e-07 - acc: 0.0906 - top_3: 0.0000e+00 - val_loss: 1.1921e-07 - val_acc: 0.1023 - val_top_3: 0.0000e+00\n",
      "Epoch 29/100\n",
      "563/563 [==============================] - 3s 5ms/step - loss: 1.1921e-07 - acc: 0.0906 - top_3: 0.0000e+00 - val_loss: 1.1921e-07 - val_acc: 0.1023 - val_top_3: 0.0000e+00\n",
      "Epoch 30/100\n",
      "563/563 [==============================] - 3s 5ms/step - loss: 1.1921e-07 - acc: 0.0906 - top_3: 0.0000e+00 - val_loss: 1.1921e-07 - val_acc: 0.1023 - val_top_3: 0.0000e+00\n",
      "Epoch 31/100\n",
      "563/563 [==============================] - 2s 4ms/step - loss: 1.1921e-07 - acc: 0.0906 - top_3: 0.0000e+00 - val_loss: 1.1921e-07 - val_acc: 0.1023 - val_top_3: 0.0000e+00\n",
      "Epoch 32/100\n",
      "563/563 [==============================] - 3s 5ms/step - loss: 1.1921e-07 - acc: 0.0906 - top_3: 0.0000e+00 - val_loss: 1.1921e-07 - val_acc: 0.1023 - val_top_3: 0.0000e+00\n",
      "Epoch 33/100\n",
      "563/563 [==============================] - 3s 5ms/step - loss: 1.1921e-07 - acc: 0.0906 - top_3: 0.0000e+00 - val_loss: 1.1921e-07 - val_acc: 0.1023 - val_top_3: 0.0000e+00\n",
      "Epoch 34/100\n",
      "563/563 [==============================] - 3s 5ms/step - loss: 1.1921e-07 - acc: 0.0906 - top_3: 0.0000e+00 - val_loss: 1.1921e-07 - val_acc: 0.1023 - val_top_3: 0.0000e+00\n",
      "Epoch 35/100\n",
      "563/563 [==============================] - 2s 4ms/step - loss: 1.1921e-07 - acc: 0.0906 - top_3: 0.0000e+00 - val_loss: 1.1921e-07 - val_acc: 0.1023 - val_top_3: 0.0000e+00\n",
      "Epoch 36/100\n",
      "563/563 [==============================] - 2s 4ms/step - loss: 1.1921e-07 - acc: 0.0906 - top_3: 0.0000e+00 - val_loss: 1.1921e-07 - val_acc: 0.1023 - val_top_3: 0.0000e+00\n",
      "Epoch 37/100\n",
      "563/563 [==============================] - 2s 3ms/step - loss: 1.1921e-07 - acc: 0.0906 - top_3: 0.0000e+00 - val_loss: 1.1921e-07 - val_acc: 0.1023 - val_top_3: 0.0000e+00\n",
      "Epoch 38/100\n",
      "563/563 [==============================] - 3s 5ms/step - loss: 1.1921e-07 - acc: 0.0906 - top_3: 0.0000e+00 - val_loss: 1.1921e-07 - val_acc: 0.1023 - val_top_3: 0.0000e+00\n",
      "Epoch 39/100\n",
      "563/563 [==============================] - 3s 5ms/step - loss: 1.1921e-07 - acc: 0.0906 - top_3: 0.0000e+00 - val_loss: 1.1921e-07 - val_acc: 0.1023 - val_top_3: 0.0000e+00\n",
      "Epoch 40/100\n",
      "563/563 [==============================] - 3s 5ms/step - loss: 1.1921e-07 - acc: 0.0906 - top_3: 0.0000e+00 - val_loss: 1.1921e-07 - val_acc: 0.1023 - val_top_3: 0.0000e+00\n",
      "Epoch 41/100\n",
      "563/563 [==============================] - 2s 4ms/step - loss: 1.1921e-07 - acc: 0.0906 - top_3: 0.0000e+00 - val_loss: 1.1921e-07 - val_acc: 0.1023 - val_top_3: 0.0000e+00\n",
      "Epoch 42/100\n",
      "563/563 [==============================] - 3s 5ms/step - loss: 1.1921e-07 - acc: 0.0906 - top_3: 0.0000e+00 - val_loss: 1.1921e-07 - val_acc: 0.1023 - val_top_3: 0.0000e+00\n",
      "Epoch 43/100\n",
      "563/563 [==============================] - 3s 5ms/step - loss: 1.1921e-07 - acc: 0.0906 - top_3: 0.0000e+00 - val_loss: 1.1921e-07 - val_acc: 0.1023 - val_top_3: 0.0000e+00\n",
      "Epoch 44/100\n",
      "563/563 [==============================] - 3s 5ms/step - loss: 1.1921e-07 - acc: 0.0906 - top_3: 0.0000e+00 - val_loss: 1.1921e-07 - val_acc: 0.1023 - val_top_3: 0.0000e+00\n",
      "Epoch 45/100\n",
      "563/563 [==============================] - 3s 5ms/step - loss: 1.1921e-07 - acc: 0.0906 - top_3: 0.0000e+00 - val_loss: 1.1921e-07 - val_acc: 0.1023 - val_top_3: 0.0000e+00\n",
      "Epoch 46/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "563/563 [==============================] - 2s 3ms/step - loss: 1.1921e-07 - acc: 0.0906 - top_3: 0.0000e+00 - val_loss: 1.1921e-07 - val_acc: 0.1023 - val_top_3: 0.0000e+00\n",
      "Epoch 47/100\n",
      "563/563 [==============================] - 2s 4ms/step - loss: 1.1921e-07 - acc: 0.0906 - top_3: 0.0000e+00 - val_loss: 1.1921e-07 - val_acc: 0.1023 - val_top_3: 0.0000e+00\n",
      "Epoch 48/100\n",
      "563/563 [==============================] - 3s 4ms/step - loss: 1.1921e-07 - acc: 0.0906 - top_3: 0.0000e+00 - val_loss: 1.1921e-07 - val_acc: 0.1023 - val_top_3: 0.0000e+00\n",
      "Epoch 49/100\n",
      "563/563 [==============================] - 3s 5ms/step - loss: 1.1921e-07 - acc: 0.0906 - top_3: 0.0000e+00 - val_loss: 1.1921e-07 - val_acc: 0.1023 - val_top_3: 0.0000e+00\n",
      "Epoch 50/100\n",
      "563/563 [==============================] - 3s 5ms/step - loss: 1.1921e-07 - acc: 0.0906 - top_3: 0.0000e+00 - val_loss: 1.1921e-07 - val_acc: 0.1023 - val_top_3: 0.0000e+00\n",
      "Epoch 51/100\n",
      "563/563 [==============================] - 3s 5ms/step - loss: 1.1921e-07 - acc: 0.0906 - top_3: 0.0000e+00 - val_loss: 1.1921e-07 - val_acc: 0.1023 - val_top_3: 0.0000e+00\n",
      "Epoch 52/100\n",
      "563/563 [==============================] - 3s 4ms/step - loss: 1.1921e-07 - acc: 0.0906 - top_3: 0.0000e+00 - val_loss: 1.1921e-07 - val_acc: 0.1023 - val_top_3: 0.0000e+00\n",
      "Epoch 53/100\n",
      "563/563 [==============================] - 3s 5ms/step - loss: 1.1921e-07 - acc: 0.0906 - top_3: 0.0000e+00 - val_loss: 1.1921e-07 - val_acc: 0.1023 - val_top_3: 0.0000e+00\n",
      "Epoch 54/100\n",
      "563/563 [==============================] - 3s 5ms/step - loss: 1.1921e-07 - acc: 0.0906 - top_3: 0.0000e+00 - val_loss: 1.1921e-07 - val_acc: 0.1023 - val_top_3: 0.0000e+00\n",
      "Epoch 55/100\n",
      "563/563 [==============================] - 2s 4ms/step - loss: 1.1921e-07 - acc: 0.0906 - top_3: 0.0000e+00 - val_loss: 1.1921e-07 - val_acc: 0.1023 - val_top_3: 0.0000e+00\n",
      "Epoch 56/100\n",
      "563/563 [==============================] - 2s 3ms/step - loss: 1.1921e-07 - acc: 0.0906 - top_3: 0.0000e+00 - val_loss: 1.1921e-07 - val_acc: 0.1023 - val_top_3: 0.0000e+00\n",
      "Epoch 57/100\n",
      "563/563 [==============================] - 3s 5ms/step - loss: 1.1921e-07 - acc: 0.0906 - top_3: 0.0000e+00 - val_loss: 1.1921e-07 - val_acc: 0.1023 - val_top_3: 0.0000e+00\n",
      "Epoch 58/100\n",
      "563/563 [==============================] - 3s 5ms/step - loss: 1.1921e-07 - acc: 0.0906 - top_3: 0.0000e+00 - val_loss: 1.1921e-07 - val_acc: 0.1023 - val_top_3: 0.0000e+00\n",
      "Epoch 59/100\n",
      "563/563 [==============================] - 3s 5ms/step - loss: 1.1921e-07 - acc: 0.0906 - top_3: 0.0000e+00 - val_loss: 1.1921e-07 - val_acc: 0.1023 - val_top_3: 0.0000e+00\n",
      "Epoch 60/100\n",
      "563/563 [==============================] - 3s 5ms/step - loss: 1.1921e-07 - acc: 0.0906 - top_3: 0.0000e+00 - val_loss: 1.1921e-07 - val_acc: 0.1023 - val_top_3: 0.0000e+00\n",
      "Epoch 61/100\n",
      "563/563 [==============================] - 3s 5ms/step - loss: 1.1921e-07 - acc: 0.0906 - top_3: 0.0000e+00 - val_loss: 1.1921e-07 - val_acc: 0.1023 - val_top_3: 0.0000e+00\n",
      "Epoch 62/100\n",
      "563/563 [==============================] - 3s 5ms/step - loss: 1.1921e-07 - acc: 0.0906 - top_3: 0.0000e+00 - val_loss: 1.1921e-07 - val_acc: 0.1023 - val_top_3: 0.0000e+00\n",
      "Epoch 63/100\n",
      "563/563 [==============================] - 3s 5ms/step - loss: 1.1921e-07 - acc: 0.0906 - top_3: 0.0000e+00 - val_loss: 1.1921e-07 - val_acc: 0.1023 - val_top_3: 0.0000e+00\n",
      "Epoch 64/100\n",
      "563/563 [==============================] - 3s 5ms/step - loss: 1.1921e-07 - acc: 0.0906 - top_3: 0.0000e+00 - val_loss: 1.1921e-07 - val_acc: 0.1023 - val_top_3: 0.0000e+00\n",
      "Epoch 65/100\n",
      "563/563 [==============================] - 2s 4ms/step - loss: 1.1921e-07 - acc: 0.0906 - top_3: 0.0000e+00 - val_loss: 1.1921e-07 - val_acc: 0.1023 - val_top_3: 0.0000e+00\n",
      "Epoch 66/100\n",
      "563/563 [==============================] - 2s 3ms/step - loss: 1.1921e-07 - acc: 0.0906 - top_3: 0.0000e+00 - val_loss: 1.1921e-07 - val_acc: 0.1023 - val_top_3: 0.0000e+00\n",
      "Epoch 67/100\n",
      "563/563 [==============================] - 3s 5ms/step - loss: 1.1921e-07 - acc: 0.0906 - top_3: 0.0000e+00 - val_loss: 1.1921e-07 - val_acc: 0.1023 - val_top_3: 0.0000e+00\n",
      "Epoch 68/100\n",
      "563/563 [==============================] - 3s 4ms/step - loss: 1.1921e-07 - acc: 0.0906 - top_3: 0.0000e+00 - val_loss: 1.1921e-07 - val_acc: 0.1023 - val_top_3: 0.0000e+00\n",
      "Epoch 69/100\n",
      "563/563 [==============================] - 3s 5ms/step - loss: 1.1921e-07 - acc: 0.0906 - top_3: 0.0000e+00 - val_loss: 1.1921e-07 - val_acc: 0.1023 - val_top_3: 0.0000e+00\n",
      "Epoch 70/100\n",
      "563/563 [==============================] - 3s 5ms/step - loss: 1.1921e-07 - acc: 0.0906 - top_3: 0.0000e+00 - val_loss: 1.1921e-07 - val_acc: 0.1023 - val_top_3: 0.0000e+00\n",
      "Epoch 71/100\n",
      "563/563 [==============================] - 3s 4ms/step - loss: 1.1921e-07 - acc: 0.0906 - top_3: 0.0000e+00 - val_loss: 1.1921e-07 - val_acc: 0.1023 - val_top_3: 0.0000e+00\n",
      "Epoch 72/100\n",
      "563/563 [==============================] - 3s 5ms/step - loss: 1.1921e-07 - acc: 0.0906 - top_3: 0.0000e+00 - val_loss: 1.1921e-07 - val_acc: 0.1023 - val_top_3: 0.0000e+00\n",
      "Epoch 73/100\n",
      "563/563 [==============================] - 3s 5ms/step - loss: 1.1921e-07 - acc: 0.0906 - top_3: 0.0000e+00 - val_loss: 1.1921e-07 - val_acc: 0.1023 - val_top_3: 0.0000e+00\n",
      "Epoch 74/100\n",
      "563/563 [==============================] - 2s 4ms/step - loss: 1.1921e-07 - acc: 0.0906 - top_3: 0.0000e+00 - val_loss: 1.1921e-07 - val_acc: 0.1023 - val_top_3: 0.0000e+00\n",
      "Epoch 75/100\n",
      "563/563 [==============================] - 2s 3ms/step - loss: 1.1921e-07 - acc: 0.0906 - top_3: 0.0000e+00 - val_loss: 1.1921e-07 - val_acc: 0.1023 - val_top_3: 0.0000e+00\n",
      "Epoch 76/100\n",
      "563/563 [==============================] - 2s 4ms/step - loss: 1.1921e-07 - acc: 0.0906 - top_3: 0.0000e+00 - val_loss: 1.1921e-07 - val_acc: 0.1023 - val_top_3: 0.0000e+00\n",
      "Epoch 77/100\n",
      "563/563 [==============================] - 3s 5ms/step - loss: 1.1921e-07 - acc: 0.0906 - top_3: 0.0000e+00 - val_loss: 1.1921e-07 - val_acc: 0.1023 - val_top_3: 0.0000e+00\n",
      "Epoch 78/100\n",
      "563/563 [==============================] - 2s 4ms/step - loss: 1.1921e-07 - acc: 0.0906 - top_3: 0.0000e+00 - val_loss: 1.1921e-07 - val_acc: 0.1023 - val_top_3: 0.0000e+00\n",
      "Epoch 79/100\n",
      "563/563 [==============================] - 3s 5ms/step - loss: 1.1921e-07 - acc: 0.0906 - top_3: 0.0000e+00 - val_loss: 1.1921e-07 - val_acc: 0.1023 - val_top_3: 0.0000e+00\n",
      "Epoch 80/100\n",
      "563/563 [==============================] - 3s 5ms/step - loss: 1.1921e-07 - acc: 0.0906 - top_3: 0.0000e+00 - val_loss: 1.1921e-07 - val_acc: 0.1023 - val_top_3: 0.0000e+00\n",
      "Epoch 81/100\n",
      "563/563 [==============================] - 3s 5ms/step - loss: 1.1921e-07 - acc: 0.0906 - top_3: 0.0000e+00 - val_loss: 1.1921e-07 - val_acc: 0.1023 - val_top_3: 0.0000e+00\n",
      "Epoch 82/100\n",
      "563/563 [==============================] - 3s 5ms/step - loss: 1.1921e-07 - acc: 0.0906 - top_3: 0.0000e+00 - val_loss: 1.1921e-07 - val_acc: 0.1023 - val_top_3: 0.0000e+00\n",
      "Epoch 83/100\n",
      "563/563 [==============================] - 3s 5ms/step - loss: 1.1921e-07 - acc: 0.0906 - top_3: 0.0000e+00 - val_loss: 1.1921e-07 - val_acc: 0.1023 - val_top_3: 0.0000e+00\n",
      "Epoch 84/100\n",
      "563/563 [==============================] - 2s 4ms/step - loss: 1.1921e-07 - acc: 0.0906 - top_3: 0.0000e+00 - val_loss: 1.1921e-07 - val_acc: 0.1023 - val_top_3: 0.0000e+00\n",
      "Epoch 85/100\n",
      "563/563 [==============================] - 2s 3ms/step - loss: 1.1921e-07 - acc: 0.0906 - top_3: 0.0000e+00 - val_loss: 1.1921e-07 - val_acc: 0.1023 - val_top_3: 0.0000e+00\n",
      "Epoch 86/100\n",
      "563/563 [==============================] - 3s 4ms/step - loss: 1.1921e-07 - acc: 0.0906 - top_3: 0.0000e+00 - val_loss: 1.1921e-07 - val_acc: 0.1023 - val_top_3: 0.0000e+00\n",
      "Epoch 87/100\n",
      "563/563 [==============================] - 3s 5ms/step - loss: 1.1921e-07 - acc: 0.0906 - top_3: 0.0000e+00 - val_loss: 1.1921e-07 - val_acc: 0.1023 - val_top_3: 0.0000e+00\n",
      "Epoch 88/100\n",
      "563/563 [==============================] - 2s 4ms/step - loss: 1.1921e-07 - acc: 0.0906 - top_3: 0.0000e+00 - val_loss: 1.1921e-07 - val_acc: 0.1023 - val_top_3: 0.0000e+00\n",
      "Epoch 89/100\n",
      "563/563 [==============================] - 3s 5ms/step - loss: 1.1921e-07 - acc: 0.0906 - top_3: 0.0000e+00 - val_loss: 1.1921e-07 - val_acc: 0.1023 - val_top_3: 0.0000e+00\n",
      "Epoch 90/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "563/563 [==============================] - 3s 5ms/step - loss: 1.1921e-07 - acc: 0.0906 - top_3: 0.0000e+00 - val_loss: 1.1921e-07 - val_acc: 0.1023 - val_top_3: 0.0000e+00\n",
      "Epoch 91/100\n",
      "563/563 [==============================] - 3s 4ms/step - loss: 1.1921e-07 - acc: 0.0906 - top_3: 0.0000e+00 - val_loss: 1.1921e-07 - val_acc: 0.1023 - val_top_3: 0.0000e+00\n",
      "Epoch 92/100\n",
      "563/563 [==============================] - 3s 5ms/step - loss: 1.1921e-07 - acc: 0.0906 - top_3: 0.0000e+00 - val_loss: 1.1921e-07 - val_acc: 0.1023 - val_top_3: 0.0000e+00\n",
      "Epoch 93/100\n",
      "563/563 [==============================] - 3s 5ms/step - loss: 1.1921e-07 - acc: 0.0906 - top_3: 0.0000e+00 - val_loss: 1.1921e-07 - val_acc: 0.1023 - val_top_3: 0.0000e+00\n",
      "Epoch 94/100\n",
      "563/563 [==============================] - 2s 4ms/step - loss: 1.1921e-07 - acc: 0.0906 - top_3: 0.0000e+00 - val_loss: 1.1921e-07 - val_acc: 0.1023 - val_top_3: 0.0000e+00\n",
      "Epoch 95/100\n",
      "563/563 [==============================] - 2s 3ms/step - loss: 1.1921e-07 - acc: 0.0906 - top_3: 0.0000e+00 - val_loss: 1.1921e-07 - val_acc: 0.1023 - val_top_3: 0.0000e+00\n",
      "Epoch 96/100\n",
      "563/563 [==============================] - 3s 5ms/step - loss: 1.1921e-07 - acc: 0.0906 - top_3: 0.0000e+00 - val_loss: 1.1921e-07 - val_acc: 0.1023 - val_top_3: 0.0000e+00\n",
      "Epoch 97/100\n",
      "563/563 [==============================] - 2s 4ms/step - loss: 1.1921e-07 - acc: 0.0906 - top_3: 0.0000e+00 - val_loss: 1.1921e-07 - val_acc: 0.1023 - val_top_3: 0.0000e+00\n",
      "Epoch 98/100\n",
      "563/563 [==============================] - 3s 5ms/step - loss: 1.1921e-07 - acc: 0.0906 - top_3: 0.0000e+00 - val_loss: 1.1921e-07 - val_acc: 0.1023 - val_top_3: 0.0000e+00\n",
      "Epoch 99/100\n",
      "563/563 [==============================] - 3s 5ms/step - loss: 1.1921e-07 - acc: 0.0906 - top_3: 0.0000e+00 - val_loss: 1.1921e-07 - val_acc: 0.1023 - val_top_3: 0.0000e+00\n",
      "Epoch 100/100\n",
      "563/563 [==============================] - 3s 4ms/step - loss: 1.1921e-07 - acc: 0.0906 - top_3: 0.0000e+00 - val_loss: 1.1921e-07 - val_acc: 0.1023 - val_top_3: 0.0000e+00\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x7f3c9f20c390>"
      ]
     },
     "execution_count": 95,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rnn.fit(X_train_2_predictions, Y_train_rnn_2, validation_data=(X_valid_predictions, Y_valid_rnn), epochs=100)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
