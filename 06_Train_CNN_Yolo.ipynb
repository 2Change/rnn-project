{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.5/dist-packages/h5py/__init__.py:36: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  from ._conv import register_converters as _register_converters\n",
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import os\n",
    "import random\n",
    "from os.path import join\n",
    "from keras import layers\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Dropout, Activation, LSTM, Bidirectional, TimeDistributed, GRU, CuDNNGRU, Conv2D, MaxPooling2D, Flatten\n",
    "from keras.utils import to_categorical\n",
    "from keras_utils import set_keras_session\n",
    "from plot_utils import plot_history\n",
    "from tqdm import tqdm\n",
    "from utils import take"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from inception_generators import train_generator_single_images, valid_generator_single_images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "set_keras_session()\n",
    "dataset = 'UCF11'\n",
    "nb_classes = int(dataset[3:])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "from inception_generators import get_dataset_split_structure, get_class_to_idx_dict\n",
    "\n",
    "def dataset_loader(dataset_dir, split_key):\n",
    "    \n",
    "    base_dir = join(dataset_dir, split_key)\n",
    "    \n",
    "    dataset_structure = get_dataset_split_structure(base_dir)\n",
    "    all_classes = dataset_structure.keys()\n",
    "    class_to_idx_dict = get_class_to_idx_dict(all_classes)\n",
    "        \n",
    "    for cl in all_classes:\n",
    "\n",
    "        class_idx = class_to_idx_dict[cl]\n",
    "        \n",
    "        video_inception_dict = {}\n",
    "\n",
    "        for video in dataset_structure[cl]:\n",
    "\n",
    "            inception_features = np.load(join(base_dir, cl, video))\n",
    "            \n",
    "            video_inception_dict[video] = inception_features\n",
    "            \n",
    "        dataset_structure[cl] = video_inception_dict\n",
    "        \n",
    "    return dataset_structure\n",
    "        \n",
    "inception_train = dataset_loader(join('datasets', dataset, 'separate_frames_30_h_240_w_320_inception'), 'train')\n",
    "inception_valid = dataset_loader(join('datasets', dataset, 'separate_frames_30_h_240_w_320_inception'), 'valid')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(2048,) (19, 19, 425)\n"
     ]
    }
   ],
   "source": [
    "frame_number = 30\n",
    "width = 320\n",
    "height = 240\n",
    "channels = 3\n",
    "padding = None\n",
    "\n",
    "dataset_name= 'separate_frames_{}_h_{}_w_{}_yolo_padding_False'.format(frame_number, height, width)\n",
    "if padding is not None:\n",
    "    dataset_name += '_padding_{}'.format(padding)\n",
    "\n",
    "\n",
    "dataset_dir = join('datasets', dataset, dataset_name)\n",
    "\n",
    "batch_size = 64\n",
    "train_generator = train_generator_single_images(dataset_dir, batch_size, additional_data=inception_train)\n",
    "valid_generator = valid_generator_single_images(dataset_dir, additional_data=inception_valid)\n",
    "\n",
    "num_train = next(train_generator) * frame_number\n",
    "num_valid = next(valid_generator)\n",
    "X_batch = next(train_generator)[0]\n",
    "\n",
    "inception_shape = X_batch[0].shape[1:]\n",
    "yolo_shape = X_batch[1].shape[1:]\n",
    "\n",
    "print(inception_shape, yolo_shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "input_2 (InputLayer)            (None, 19, 19, 425)  0                                            \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_1 (Conv2D)               (None, 19, 19, 32)   340032      input_2[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_2 (Conv2D)               (None, 19, 19, 64)   18496       conv2d_1[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling2d_1 (MaxPooling2D)  (None, 9, 9, 64)     0           conv2d_2[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "dropout_1 (Dropout)             (None, 9, 9, 64)     0           max_pooling2d_1[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_3 (Conv2D)               (None, 9, 9, 128)    73856       dropout_1[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling2d_2 (MaxPooling2D)  (None, 4, 4, 128)    0           conv2d_3[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "flatten_1 (Flatten)             (None, 2048)         0           max_pooling2d_2[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "input_1 (InputLayer)            (None, 2048)         0                                            \n",
      "__________________________________________________________________________________________________\n",
      "dense_1 (Dense)                 (None, 512)          1049088     flatten_1[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_1 (Concatenate)     (None, 2560)         0           input_1[0][0]                    \n",
      "                                                                 dense_1[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "dropout_2 (Dropout)             (None, 2560)         0           concatenate_1[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "dense_2 (Dense)                 (None, 512)          1311232     dropout_2[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "dropout_3 (Dropout)             (None, 512)          0           dense_2[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "dense_3 (Dense)                 (None, 101)          51813       dropout_3[0][0]                  \n",
      "==================================================================================================\n",
      "Total params: 2,844,517\n",
      "Trainable params: 2,844,517\n",
      "Non-trainable params: 0\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "from keras.applications.inception_v3 import InceptionV3\n",
    "from keras.applications.densenet import DenseNet121\n",
    "from keras.models import Model\n",
    "from keras import backend as K\n",
    "from keras import regularizers\n",
    "from keras.layers import Lambda, Reshape\n",
    "from keras import layers\n",
    "\n",
    "inception_input = layers.Input(inception_shape)\n",
    "inception_net = inception_input\n",
    "\n",
    "yolo_input = layers.Input(yolo_shape)\n",
    "\n",
    "x = yolo_input\n",
    "x = Conv2D(128, (5,5), activation='relu', padding='same')(x)\n",
    "x = Conv2D(64, (3,3), activation='relu', padding='same')(x)\n",
    "x = MaxPooling2D()(x)\n",
    "x = Dropout(0.2)(x)\n",
    "x = Conv2D(128, (3,3), activation='relu', padding='same')(x)\n",
    "x = MaxPooling2D()(x)  \n",
    "x = Flatten()(x)\n",
    "x = Dense(512, activation='relu')(x)\n",
    "                    \n",
    "x = layers.concatenate([inception_net, x])\n",
    "#x = Flatten()(x)\n",
    "x = Dropout(0.5)(x)\n",
    "x = Dense(512, activation='relu')(x)\n",
    "x = Dropout(0.25)(x)\n",
    "x = layers.Dense(nb_classes, activation='softmax')(x)\n",
    "                    \n",
    "model = Model(inputs=[inception_input, yolo_input], outputs=[x])\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "from keras import metrics, callbacks, optimizers\n",
    "from functools import partial\n",
    "\n",
    "top_3_k_categorical_accuracy = partial(metrics.top_k_categorical_accuracy, k=3)\n",
    "top_3_k_categorical_accuracy.__name__ = 'top_3'\n",
    "\n",
    "early_stopper = callbacks.EarlyStopping(patience=5)\n",
    "reduce_lr = callbacks.ReduceLROnPlateau(patience=5, factor=0.75)\n",
    "\n",
    "sgd = optimizers.SGD(momentum=0.9, nesterov=True, lr=0.001)\n",
    "#sgd = optimizers.SGD(momentum=0.9, lr=0.001)\n",
    "adam = optimizers.Adam(lr=0.00005)\n",
    "\n",
    "model.compile(optimizer=sgd, loss='categorical_crossentropy', \n",
    "              metrics=['accuracy', top_3_k_categorical_accuracy])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_model(**kwargs):\n",
    "    return model.fit_generator(train_generator,\n",
    "                    steps_per_epoch=num_train, \n",
    "                    validation_data=valid_generator,\n",
    "                    validation_steps=num_valid,\n",
    "                    epochs=kwargs.get('epochs', 50))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50\n",
      " 131/2250 [>.............................] - ETA: 2:58:33 - loss: 4.6467 - acc: 0.0292 - top_3: 0.0681"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-9-bf04ed75ab77>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mhistory\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtrain_model\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m<ipython-input-8-68b2e8c2281c>\u001b[0m in \u001b[0;36mtrain_model\u001b[0;34m(**kwargs)\u001b[0m\n\u001b[1;32m      4\u001b[0m                     \u001b[0mvalidation_data\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mvalid_generator\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m                     \u001b[0mvalidation_steps\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mnum_valid\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 6\u001b[0;31m                     epochs=kwargs.get('epochs', 50))\n\u001b[0m",
      "\u001b[0;32m/usr/local/lib/python3.5/dist-packages/keras/legacy/interfaces.py\u001b[0m in \u001b[0;36mwrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     89\u001b[0m                 warnings.warn('Update your `' + object_name +\n\u001b[1;32m     90\u001b[0m                               '` call to the Keras 2 API: ' + signature, stacklevel=2)\n\u001b[0;32m---> 91\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     92\u001b[0m         \u001b[0mwrapper\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_original_function\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     93\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mwrapper\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.5/dist-packages/keras/engine/training.py\u001b[0m in \u001b[0;36mfit_generator\u001b[0;34m(self, generator, steps_per_epoch, epochs, verbose, callbacks, validation_data, validation_steps, class_weight, max_queue_size, workers, use_multiprocessing, shuffle, initial_epoch)\u001b[0m\n\u001b[1;32m   2210\u001b[0m                 \u001b[0mbatch_index\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2211\u001b[0m                 \u001b[0;32mwhile\u001b[0m \u001b[0msteps_done\u001b[0m \u001b[0;34m<\u001b[0m \u001b[0msteps_per_epoch\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2212\u001b[0;31m                     \u001b[0mgenerator_output\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnext\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moutput_generator\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2213\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2214\u001b[0m                     \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mhasattr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mgenerator_output\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'__len__'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.5/dist-packages/keras/utils/data_utils.py\u001b[0m in \u001b[0;36mget\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    771\u001b[0m                     \u001b[0;32mraise\u001b[0m \u001b[0mStopIteration\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    772\u001b[0m                 \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 773\u001b[0;31m                     \u001b[0mtime\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msleep\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwait_time\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    774\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    775\u001b[0m         \u001b[0;31m# Make sure to rethrow the first exception in the queue, if any\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "history = train_model()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def collect_statistics_on_videos():\n",
    "\n",
    "    from collections import Counter\n",
    "\n",
    "    count_videos = 0\n",
    "    count_top_1 = 0\n",
    "    count_top_3 = 0\n",
    "    count_top_1_argmax = 0\n",
    "\n",
    "    for frames, labels in tqdm(take(valid_generator, num_valid), total=num_valid):\n",
    "\n",
    "        ### Compute the predicted labels using the model\n",
    "\n",
    "        true_labels = labels[0]\n",
    "        true_label_idx = np.argmax(true_labels)\n",
    "        predicted_labels = model.predict(frames)\n",
    "\n",
    "        ### Update counters with Approach 1 (mean)\n",
    "\n",
    "        predicted_labels_mean = np.mean(predicted_labels, axis=0)\n",
    "        predicted_labels_mean_idx = np.argmax(predicted_labels_mean)\n",
    "        idx_sorted_top_3 = np.argsort(predicted_labels_mean)[-3:]\n",
    "\n",
    "        if true_label_idx in idx_sorted_top_3:\n",
    "            count_top_3 += 1\n",
    "\n",
    "        if true_label_idx == predicted_labels_mean_idx:\n",
    "            count_top_1 += 1\n",
    "\n",
    "        ### Update count with Approach 2 (highest count)\n",
    "\n",
    "        predicted_labels_argmax = np.argmax(predicted_labels, axis=1)\n",
    "        counter = Counter(predicted_labels_argmax)\n",
    "\n",
    "        if counter.most_common(1)[0][0] == true_label_idx:\n",
    "            count_top_1_argmax += 1\n",
    "\n",
    "        ### Update number of videos\n",
    "\n",
    "        count_videos += 1\n",
    "        \n",
    "        \n",
    "    print('Top 1 accuracy (using mean):', count_top_1 / count_videos)\n",
    "    print('Top 3 accuracy (using mean):', count_top_3 / count_videos)\n",
    "    print('Top 1 accuracy (using highest count):', count_top_1_argmax / count_videos)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "collect_statistics_on_videos()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
