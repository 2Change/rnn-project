{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Train on separate images (CNN-Only) on InceptionV3 output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.5/dist-packages/h5py/__init__.py:36: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  from ._conv import register_converters as _register_converters\n",
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import h5py\n",
    "import numpy as np\n",
    "import os\n",
    "import random\n",
    "from os.path import join\n",
    "from keras import layers\n",
    "from keras.models import Model\n",
    "from keras.utils import to_categorical"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = 'UCF11'\n",
    "nb_classes = int(dataset[3:])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_generator(dataset_dir, batch_size):\n",
    "    \n",
    "    all_files = os.listdir(dataset_dir)\n",
    "    \n",
    "    while True:\n",
    "        images = []\n",
    "        labels = []\n",
    "\n",
    "        for _ in range(batch_size):\n",
    "            \n",
    "            random_filename = random.choice(all_files)\n",
    "            \n",
    "            with h5py.File(join(dataset_dir, random_filename), 'r') as hf:\n",
    "                frames = hf['inception'][:]\n",
    "                fr_labels = hf['Y'][:]\n",
    "                random_idx = np.random.randint(frames.shape[0])\n",
    "                \n",
    "                images.append(frames[random_idx])\n",
    "                labels.append(fr_labels)\n",
    "                \n",
    "        images = np.array(images)\n",
    "        labels = to_categorical(np.array(labels), nb_classes)\n",
    "        \n",
    "        yield images, labels\n",
    "        \n",
    "        \n",
    "\n",
    "def valid_generator(dataset_dir, batch_size):\n",
    "    \n",
    "    all_files = os.listdir(dataset_dir)\n",
    "    \n",
    "    while True:\n",
    "        \n",
    "        for filename in all_files:\n",
    "\n",
    "            with h5py.File(join(dataset_dir, filename), 'r') as hf:\n",
    "                frames = hf['inception'][:]\n",
    "                single_label = hf['Y'][:][0]\n",
    "\n",
    "                fr_labels = np.array([single_label] * frames.shape[0])\n",
    "\n",
    "                yield frames, to_categorical(fr_labels, nb_classes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Inception output shape is (2, 3, 2048)\n"
     ]
    }
   ],
   "source": [
    "separate_dataset_dir = join('datasets', dataset, 'separate_frames_50_h_120_w_160')\n",
    "train_dir = join(separate_dataset_dir, 'train')\n",
    "valid_dir = join(separate_dataset_dir, 'valid')\n",
    "\n",
    "train_samples_count = len(os.listdir(train_dir))\n",
    "valid_samples_count = len(os.listdir(valid_dir))\n",
    "\n",
    "with h5py.File(join(train_dir, os.listdir(train_dir)[0])) as hf:\n",
    "    inception_shape = hf['inception'][:].shape[1:]\n",
    "    print('Inception output shape is', inception_shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_1 (InputLayer)         (None, 2, 3, 2048)        0         \n",
      "_________________________________________________________________\n",
      "global_average_pooling2d_1 ( (None, 2048)              0         \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 1024)              2098176   \n",
      "_________________________________________________________________\n",
      "dropout_1 (Dropout)          (None, 1024)              0         \n",
      "_________________________________________________________________\n",
      "dense_2 (Dense)              (None, 11)                11275     \n",
      "=================================================================\n",
      "Total params: 2,109,451\n",
      "Trainable params: 2,109,451\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "input_layer = layers.Input(inception_shape)\n",
    "x = input_layer\n",
    "x = layers.GlobalAveragePooling2D()(x)\n",
    "x = layers.Dense(1024, activation='relu')(x)\n",
    "x = layers.Dropout(0.5)(x)\n",
    "x = layers.Dense(nb_classes, activation='softmax')(x)\n",
    "\n",
    "# this is the model we will train\n",
    "model = Model(inputs=input_layer, outputs=x)\n",
    "print(model.summary())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 128\n",
    "\n",
    "from keras import metrics\n",
    "from functools import partial\n",
    "\n",
    "top_3_k_categorical_accuracy = partial(metrics.top_k_categorical_accuracy, k=3)\n",
    "top_3_k_categorical_accuracy.__name__ = 'top_3'\n",
    "\n",
    "model.compile(optimizer='adam', loss='categorical_crossentropy', \n",
    "              metrics=['accuracy', top_3_k_categorical_accuracy])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/20\n",
      "369/369 [==============================] - 79s 214ms/step - loss: 0.3833 - acc: 0.8900 - top_3: 0.9682 - val_loss: 1.4876 - val_acc: 0.6314 - val_top_3: 0.8103\n",
      "Epoch 2/20\n",
      "369/369 [==============================] - 75s 204ms/step - loss: 0.1069 - acc: 0.9661 - top_3: 0.9967 - val_loss: 1.6292 - val_acc: 0.6435 - val_top_3: 0.8334\n",
      "Epoch 3/20\n",
      "369/369 [==============================] - 76s 206ms/step - loss: 0.0740 - acc: 0.9755 - top_3: 0.9979 - val_loss: 1.9972 - val_acc: 0.6237 - val_top_3: 0.8137\n",
      "Epoch 4/20\n",
      "369/369 [==============================] - 77s 208ms/step - loss: 0.0679 - acc: 0.9785 - top_3: 0.9986 - val_loss: 2.0168 - val_acc: 0.6179 - val_top_3: 0.8138\n",
      "Epoch 5/20\n",
      "369/369 [==============================] - 77s 207ms/step - loss: 0.0580 - acc: 0.9805 - top_3: 0.9986 - val_loss: 2.0045 - val_acc: 0.6266 - val_top_3: 0.8363\n",
      "Epoch 6/20\n",
      "369/369 [==============================] - 74s 201ms/step - loss: 0.0534 - acc: 0.9815 - top_3: 0.9991 - val_loss: 2.0960 - val_acc: 0.6234 - val_top_3: 0.8291\n",
      "Epoch 7/20\n",
      "369/369 [==============================] - 75s 202ms/step - loss: 0.0525 - acc: 0.9826 - top_3: 0.9990 - val_loss: 2.3761 - val_acc: 0.6117 - val_top_3: 0.8168\n",
      "Epoch 8/20\n",
      "369/369 [==============================] - 75s 203ms/step - loss: 0.0463 - acc: 0.9853 - top_3: 0.9993 - val_loss: 2.4098 - val_acc: 0.6139 - val_top_3: 0.8168\n",
      "Epoch 9/20\n",
      "369/369 [==============================] - 75s 202ms/step - loss: 0.0479 - acc: 0.9845 - top_3: 0.9993 - val_loss: 3.1050 - val_acc: 0.6233 - val_top_3: 0.8080\n",
      "Epoch 10/20\n",
      "369/369 [==============================] - 73s 197ms/step - loss: 0.0470 - acc: 0.9852 - top_3: 0.9991 - val_loss: 2.6161 - val_acc: 0.6266 - val_top_3: 0.8208\n",
      "Epoch 11/20\n",
      "369/369 [==============================] - 76s 205ms/step - loss: 0.0374 - acc: 0.9878 - top_3: 0.9994 - val_loss: 2.7070 - val_acc: 0.6187 - val_top_3: 0.8215\n",
      "Epoch 12/20\n",
      "369/369 [==============================] - 75s 203ms/step - loss: 0.0418 - acc: 0.9871 - top_3: 0.9994 - val_loss: 3.0852 - val_acc: 0.6276 - val_top_3: 0.8093\n",
      "Epoch 13/20\n",
      "369/369 [==============================] - 75s 204ms/step - loss: 0.0429 - acc: 0.9868 - top_3: 0.9994 - val_loss: 2.7958 - val_acc: 0.6314 - val_top_3: 0.8118\n",
      "Epoch 14/20\n",
      "369/369 [==============================] - 74s 201ms/step - loss: 0.0398 - acc: 0.9882 - top_3: 0.9996 - val_loss: 2.4002 - val_acc: 0.6608 - val_top_3: 0.8522\n",
      "Epoch 15/20\n",
      "369/369 [==============================] - 75s 204ms/step - loss: 0.0331 - acc: 0.9891 - top_3: 0.9996 - val_loss: 2.6490 - val_acc: 0.6291 - val_top_3: 0.8491\n",
      "Epoch 16/20\n",
      "369/369 [==============================] - 74s 202ms/step - loss: 0.0411 - acc: 0.9880 - top_3: 0.9994 - val_loss: 3.2181 - val_acc: 0.6348 - val_top_3: 0.8155\n",
      "Epoch 17/20\n",
      "280/369 [=====================>........] - ETA: 16s - loss: 0.0469 - acc: 0.9865 - top_3: 0.9993 ETA: 17s - loss: 0.0471 - acc: 0.9864 - top_3: 0."
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-7-fc0cdbd0c45d>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      3\u001b[0m                     \u001b[0mvalidation_data\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mvalid_generator\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvalid_dir\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch_size\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m                     \u001b[0mvalidation_steps\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mvalid_samples_count\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 5\u001b[0;31m                     epochs=20)\n\u001b[0m",
      "\u001b[0;32m/usr/local/lib/python3.5/dist-packages/keras/legacy/interfaces.py\u001b[0m in \u001b[0;36mwrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     89\u001b[0m                 warnings.warn('Update your `' + object_name +\n\u001b[1;32m     90\u001b[0m                               '` call to the Keras 2 API: ' + signature, stacklevel=2)\n\u001b[0;32m---> 91\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     92\u001b[0m         \u001b[0mwrapper\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_original_function\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     93\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mwrapper\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.5/dist-packages/keras/engine/training.py\u001b[0m in \u001b[0;36mfit_generator\u001b[0;34m(self, generator, steps_per_epoch, epochs, verbose, callbacks, validation_data, validation_steps, class_weight, max_queue_size, workers, use_multiprocessing, shuffle, initial_epoch)\u001b[0m\n\u001b[1;32m   2210\u001b[0m                 \u001b[0mbatch_index\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2211\u001b[0m                 \u001b[0;32mwhile\u001b[0m \u001b[0msteps_done\u001b[0m \u001b[0;34m<\u001b[0m \u001b[0msteps_per_epoch\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2212\u001b[0;31m                     \u001b[0mgenerator_output\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnext\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moutput_generator\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2213\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2214\u001b[0m                     \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mhasattr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mgenerator_output\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'__len__'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.5/dist-packages/keras/utils/data_utils.py\u001b[0m in \u001b[0;36mget\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    771\u001b[0m                     \u001b[0;32mraise\u001b[0m \u001b[0mStopIteration\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    772\u001b[0m                 \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 773\u001b[0;31m                     \u001b[0mtime\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msleep\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwait_time\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    774\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    775\u001b[0m         \u001b[0;31m# Make sure to rethrow the first exception in the queue, if any\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "history = model.fit_generator(train_generator(train_dir, batch_size),\n",
    "                    steps_per_epoch=train_samples_count * 50 // batch_size, \n",
    "                    validation_data=valid_generator(valid_dir, batch_size),\n",
    "                    validation_steps=valid_samples_count,\n",
    "                    epochs=20)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
