{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Train on separate images (CNN-Only) on InceptionV3 output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.5/dist-packages/h5py/__init__.py:36: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  from ._conv import register_converters as _register_converters\n",
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import h5py\n",
    "import numpy as np\n",
    "import os\n",
    "import random\n",
    "from os.path import join\n",
    "from keras import layers\n",
    "from keras.models import Model\n",
    "from keras.utils import to_categorical"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = 'UCF11'\n",
    "nb_classes = int(dataset[3:])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_generator(dataset_dir, batch_size):\n",
    "    \n",
    "    all_files = os.listdir(dataset_dir)\n",
    "    \n",
    "    while True:\n",
    "        images = []\n",
    "        labels = []\n",
    "\n",
    "        for _ in range(batch_size):\n",
    "            \n",
    "            random_filename = random.choice(all_files)\n",
    "            \n",
    "            with h5py.File(join(dataset_dir, random_filename), 'r') as hf:\n",
    "                frames = hf['inception'][:]\n",
    "                fr_labels = hf['Y'][:]\n",
    "                random_idx = np.random.randint(frames.shape[0])\n",
    "                \n",
    "                images.append(frames[random_idx])\n",
    "                labels.append(fr_labels)\n",
    "                \n",
    "        images = np.array(images)\n",
    "        labels = to_categorical(np.array(labels), nb_classes)\n",
    "        \n",
    "        yield images, labels\n",
    "        \n",
    "        \n",
    "\n",
    "def valid_generator(dataset_dir, batch_size):\n",
    "    \n",
    "    all_files = os.listdir(dataset_dir)\n",
    "    \n",
    "    while True:\n",
    "        \n",
    "        for filename in all_files:\n",
    "\n",
    "            with h5py.File(join(dataset_dir, filename), 'r') as hf:\n",
    "                frames = hf['inception'][:]\n",
    "                single_label = hf['Y'][:][0]\n",
    "\n",
    "                fr_labels = np.array([single_label] * frames.shape[0])\n",
    "\n",
    "                yield frames, to_categorical(fr_labels, nb_classes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Inception output shape is (2, 3, 2048)\n"
     ]
    }
   ],
   "source": [
    "separate_dataset_dir = join('datasets', dataset, 'separate_frames_50_h_120_w_160')\n",
    "train_dir = join(separate_dataset_dir, 'train')\n",
    "valid_dir = join(separate_dataset_dir, 'valid')\n",
    "\n",
    "train_samples_count = len(os.listdir(train_dir))\n",
    "valid_samples_count = len(os.listdir(valid_dir))\n",
    "\n",
    "with h5py.File(join(train_dir, os.listdir(train_dir)[0])) as hf:\n",
    "    inception_shape = hf['inception'][:].shape[1:]\n",
    "    print('Inception output shape is', inception_shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_1 (InputLayer)         (None, 2, 3, 2048)        0         \n",
      "_________________________________________________________________\n",
      "global_average_pooling2d_1 ( (None, 2048)              0         \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 1024)              2098176   \n",
      "_________________________________________________________________\n",
      "dropout_1 (Dropout)          (None, 1024)              0         \n",
      "_________________________________________________________________\n",
      "dense_2 (Dense)              (None, 11)                11275     \n",
      "=================================================================\n",
      "Total params: 2,109,451\n",
      "Trainable params: 2,109,451\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "input_layer = layers.Input(inception_shape)\n",
    "x = input_layer\n",
    "x = layers.GlobalAveragePooling2D()(x)\n",
    "x = layers.Dense(1024, activation='relu')(x)\n",
    "x = layers.Dropout(0.5)(x)\n",
    "x = layers.Dense(nb_classes, activation='softmax')(x)\n",
    "\n",
    "# this is the model we will train\n",
    "model = Model(inputs=input_layer, outputs=x)\n",
    "print(model.summary())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 64\n",
    "\n",
    "from keras import metrics\n",
    "from functools import partial\n",
    "\n",
    "top_3_k_categorical_accuracy = partial(metrics.top_k_categorical_accuracy, k=3)\n",
    "top_3_k_categorical_accuracy.__name__ = 'top_3'\n",
    "\n",
    "model.compile(optimizer='sgd', loss='categorical_crossentropy', \n",
    "              metrics=['accuracy', top_3_k_categorical_accuracy])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/20\n",
      "739/739 [==============================] - 83s 112ms/step - loss: 0.5851 - acc: 0.8212 - top_3: 0.9418 - val_loss: 1.3253 - val_acc: 0.5948 - val_top_3: 0.8116 1:26 - loss - ETA: 43s - loss:  - ETA: 40s -  - ETA: 20s -  - ETA: 17s - loss: 0.6633 - acc: 0. - ETA: 16s - loss: 0.6575 - acc: 0.7982 - top - ETA: 16s  - ETA: 13s - loss: 0.6422 - acc:  - ETA: 8s - loss: 0.61 - ETA: 4s -\n",
      "Epoch 2/20\n",
      "739/739 [==============================] - 72s 97ms/step - loss: 0.2104 - acc: 0.9380 - top_3: 0.9909 - val_loss: 1.3611 - val_acc: 0.6086 - val_top_3: 0.8162\n",
      "Epoch 3/20\n",
      "739/739 [==============================] - 72s 98ms/step - loss: 0.1476 - acc: 0.9575 - top_3: 0.9949 - val_loss: 1.3478 - val_acc: 0.6184 - val_top_3: 0.8184\n",
      "Epoch 4/20\n",
      "739/739 [==============================] - 72s 98ms/step - loss: 0.1060 - acc: 0.9705 - top_3: 0.9972 - val_loss: 1.3589 - val_acc: 0.6280 - val_top_3: 0.8253oss: 0.1063 - acc: 0.9705 - top_3: 0.9 - ETA: 0s - loss: 0.1062 - acc: 0.9705 - top_3: 0.997 - ETA: 0s - loss: 0.1062 - acc: 0.9705 - top_3: 0.\n",
      "Epoch 5/20\n",
      "739/739 [==============================] - 72s 97ms/step - loss: 0.0872 - acc: 0.9758 - top_3: 0.9979 - val_loss: 1.4349 - val_acc: 0.6217 - val_top_3: 0.8233\n",
      "Epoch 6/20\n",
      "739/739 [==============================] - 73s 99ms/step - loss: 0.0705 - acc: 0.9807 - top_3: 0.9983 - val_loss: 1.4138 - val_acc: 0.6308 - val_top_3: 0.8293\n",
      "Epoch 7/20\n",
      "739/739 [==============================] - 73s 98ms/step - loss: 0.0606 - acc: 0.9842 - top_3: 0.9988 - val_loss: 1.4242 - val_acc: 0.6318 - val_top_3: 0.8344\n",
      "Epoch 8/20\n",
      "739/739 [==============================] - 73s 98ms/step - loss: 0.0519 - acc: 0.9868 - top_3: 0.9992 - val_loss: 1.4605 - val_acc: 0.6300 - val_top_3: 0.8329oss: 0.0520 - acc: 0.9867 - top_3: 0.9 - ETA: 0s - loss: 0.0519 - acc: 0.9868 - top_3: 0.99\n",
      "Epoch 9/20\n",
      "739/739 [==============================] - 73s 98ms/step - loss: 0.0440 - acc: 0.9891 - top_3: 0.9992 - val_loss: 1.4951 - val_acc: 0.6346 - val_top_3: 0.8319\n",
      "Epoch 10/20\n",
      "739/739 [==============================] - 73s 99ms/step - loss: 0.0390 - acc: 0.9901 - top_3: 0.9995 - val_loss: 1.5128 - val_acc: 0.6359 - val_top_3: 0.83140399 - acc - ETA: 51s - loss: 0.0397 - acc: 0. - ETA: 51s - loss: 0.0396 - acc: 0.9900 - top_3: 0.99 - ETA: 50s - loss: 0.0396 - acc: 0.9901 - top - ETA: 50s - loss: 0.0400 - acc: 0.9899 - top_3 - ETA: 50s - loss: 0. - ETA: 48s - loss: 0.0397 - acc: 0.9901 - top_3: 0. - ETA: 48s - loss: 0.0398 - acc: 0.9901 - top_3 - ETA: 48s - loss: 0.0403 - acc: 0.9900 - top_3: 0.99 - ETA: 48s - loss: 0.0402 - acc: 0.9900 - top - ETA: 47s - loss: 0.0401 - acc: 0.9900 - top_3: 0.99 - ETA: 47s - loss: 0.0402 - acc: 0.9900 - top_3: 0.99 - ETA: 47s - loss: 0.0402 - acc: 0.9898 - top_3 - ETA: 47s - loss: 0.0403 - acc: 0.9898 - ETA: 46s - loss: 0.0405 - acc: 0.9898 - top_3: 0. - ETA: 46s - loss: 0.0407 - acc: 0.9896 - top_3: 0.99 - ETA: 46s - l\n",
      "Epoch 11/20\n",
      "739/739 [==============================] - 73s 98ms/step - loss: 0.0342 - acc: 0.9919 - top_3: 0.9996 - val_loss: 1.5146 - val_acc: 0.6331 - val_top_3: 0.8281\n",
      "Epoch 12/20\n",
      "739/739 [==============================] - 72s 97ms/step - loss: 0.0317 - acc: 0.9927 - top_3: 0.9997 - val_loss: 1.4984 - val_acc: 0.6427 - val_top_3: 0.8314\n",
      "Epoch 13/20\n",
      "739/739 [==============================] - 72s 97ms/step - loss: 0.0285 - acc: 0.9929 - top_3: 0.9998 - val_loss: 1.5452 - val_acc: 0.6394 - val_top_3: 0.8343\n",
      "Epoch 14/20\n",
      "739/739 [==============================] - 73s 99ms/step - loss: 0.0260 - acc: 0.9942 - top_3: 0.9997 - val_loss: 1.5591 - val_acc: 0.6357 - val_top_3: 0.8305\n",
      "Epoch 15/20\n",
      "739/739 [==============================] - 72s 98ms/step - loss: 0.0229 - acc: 0.9951 - top_3: 0.9999 - val_loss: 1.5733 - val_acc: 0.6408 - val_top_3: 0.8326\n",
      "Epoch 16/20\n",
      "739/739 [==============================] - 73s 99ms/step - loss: 0.0219 - acc: 0.9952 - top_3: 0.9998 - val_loss: 1.5893 - val_acc: 0.6394 - val_top_3: 0.8275\n",
      "Epoch 17/20\n",
      "739/739 [==============================] - 72s 98ms/step - loss: 0.0203 - acc: 0.9953 - top_3: 0.9998 - val_loss: 1.6015 - val_acc: 0.6389 - val_top_3: 0.8297\n",
      "Epoch 18/20\n",
      "739/739 [==============================] - 72s 98ms/step - loss: 0.0198 - acc: 0.9956 - top_3: 0.9999 - val_loss: 1.6231 - val_acc: 0.6322 - val_top_3: 0.8269\n",
      "Epoch 19/20\n",
      "739/739 [==============================] - 73s 98ms/step - loss: 0.0183 - acc: 0.9963 - top_3: 0.9999 - val_loss: 1.6248 - val_acc: 0.6381 - val_top_3: 0.8325\n",
      "Epoch 20/20\n",
      "739/739 [==============================] - 72s 98ms/step - loss: 0.0164 - acc: 0.9967 - top_3: 0.9999 - val_loss: 1.6440 - val_acc: 0.6337 - val_top_3: 0.8281\n"
     ]
    }
   ],
   "source": [
    "history = model.fit_generator(train_generator(train_dir, batch_size),\n",
    "                    steps_per_epoch=train_samples_count * 50 // batch_size, \n",
    "                    validation_data=valid_generator(valid_dir, batch_size),\n",
    "                    validation_steps=valid_samples_count,\n",
    "                    epochs=20)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
