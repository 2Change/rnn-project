{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.5/dist-packages/h5py/__init__.py:36: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  from ._conv import register_converters as _register_converters\n",
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import os\n",
    "import random\n",
    "from os.path import join\n",
    "from keras import layers\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Dropout, Activation, LSTM, Bidirectional, TimeDistributed, GRU, CuDNNGRU, Conv2D, MaxPooling2D, Flatten\n",
    "from keras.utils import to_categorical\n",
    "from keras_utils import set_keras_session\n",
    "from inception_generators import frames_generator_rnn,load_whole_dataset\n",
    "from plot_utils import plot_history"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "set_keras_session()\n",
    "dataset = 'UCF11'\n",
    "nb_classes = int(dataset[3:])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from inception_generators import get_dataset_split_structure, get_class_to_idx_dict\n",
    "\n",
    "def dataset_loader(dataset_dir, split_key):\n",
    "    \n",
    "    base_dir = join(dataset_dir, split_key)\n",
    "    \n",
    "    dataset_structure = get_dataset_split_structure(base_dir)\n",
    "    all_classes = dataset_structure.keys()\n",
    "    class_to_idx_dict = get_class_to_idx_dict(all_classes)\n",
    "        \n",
    "    for cl in all_classes:\n",
    "\n",
    "        class_idx = class_to_idx_dict[cl]\n",
    "        \n",
    "        video_inception_dict = {}\n",
    "\n",
    "        for video in dataset_structure[cl]:\n",
    "\n",
    "            inception_features = np.load(join(base_dir, cl, video))\n",
    "            \n",
    "            video_inception_dict[video] = inception_features\n",
    "            \n",
    "        dataset_structure[cl] = video_inception_dict\n",
    "        \n",
    "    return dataset_structure\n",
    "        \n",
    "inception_train = dataset_loader(join('datasets', dataset, 'separate_frames_50_h_240_w_320_inception'), 'train')\n",
    "inception_valid = dataset_loader(join('datasets', dataset, 'separate_frames_50_h_240_w_320_inception'), 'valid')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(50, 2048) (50, 19, 19, 425)\n"
     ]
    }
   ],
   "source": [
    "frame_number = 50\n",
    "width = 320\n",
    "height = 240\n",
    "channels = 3\n",
    "padding = None\n",
    "\n",
    "dataset_name= 'separate_frames_{}_h_{}_w_{}_yolo_padding_False'.format(frame_number, height, width)\n",
    "if padding is not None:\n",
    "    dataset_name += '_padding_{}'.format(padding)\n",
    "\n",
    "\n",
    "dataset_dir = join('datasets', dataset, dataset_name)\n",
    "\n",
    "batch_size = 16\n",
    "train_generator = frames_generator_rnn(dataset_dir, 'train', batch_size, inception_train)\n",
    "valid_generator = frames_generator_rnn(dataset_dir, 'valid', batch_size, inception_valid)\n",
    "\n",
    "num_train, num_valid = next(train_generator), next(valid_generator)\n",
    "X_batch = next(train_generator)[0]\n",
    "\n",
    "inception_shape = X_batch[0].shape[1:]\n",
    "yolo_shape = X_batch[1].shape[1:]\n",
    "\n",
    "print(inception_shape, yolo_shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "input_2 (InputLayer)            (None, 50, 19, 19, 4 0                                            \n",
      "__________________________________________________________________________________________________\n",
      "time_distributed_1 (TimeDistrib (None, 50, 19, 19, 3 340032      input_2[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "time_distributed_2 (TimeDistrib (None, 50, 19, 19, 6 18496       time_distributed_1[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "time_distributed_3 (TimeDistrib (None, 50, 9, 9, 64) 0           time_distributed_2[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "time_distributed_4 (TimeDistrib (None, 50, 9, 9, 64) 0           time_distributed_3[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "time_distributed_5 (TimeDistrib (None, 50, 9, 9, 128 73856       time_distributed_4[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "time_distributed_6 (TimeDistrib (None, 50, 4, 4, 128 0           time_distributed_5[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "input_1 (InputLayer)            (None, 50, 2048)     0                                            \n",
      "__________________________________________________________________________________________________\n",
      "time_distributed_7 (TimeDistrib (None, 50, 2048)     0           time_distributed_6[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "dense_1 (Dense)                 (None, 50, 128)      262272      input_1[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "time_distributed_8 (TimeDistrib (None, 50, 128)      262272      time_distributed_7[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_1 (Concatenate)     (None, 50, 256)      0           dense_1[0][0]                    \n",
      "                                                                 time_distributed_8[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "dropout_2 (Dropout)             (None, 50, 256)      0           concatenate_1[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "lstm_1 (LSTM)                   (None, 256)          525312      dropout_2[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "dense_3 (Dense)                 (None, 11)           2827        lstm_1[0][0]                     \n",
      "==================================================================================================\n",
      "Total params: 1,485,067\n",
      "Trainable params: 1,485,067\n",
      "Non-trainable params: 0\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "from keras.applications.inception_v3 import InceptionV3\n",
    "from keras.applications.densenet import DenseNet121\n",
    "from keras.models import Model\n",
    "from keras import backend as K\n",
    "from keras import regularizers\n",
    "from keras.layers import Lambda, Reshape\n",
    "from keras import layers\n",
    "\n",
    "inception_input = layers.Input(inception_shape)\n",
    "inception_net = Dense(128, activation='relu')(inception_input)\n",
    "\n",
    "yolo_input = layers.Input(yolo_shape)\n",
    "\n",
    "x = yolo_input\n",
    "x = TimeDistributed(Conv2D(32, (5,5), activation='relu', padding='same'))(x)\n",
    "x = TimeDistributed(Conv2D(64, (3,3), activation='relu', padding='same'))(x)\n",
    "x = TimeDistributed(MaxPooling2D())(x)\n",
    "x = TimeDistributed(Dropout(0.2))(x)\n",
    "x = TimeDistributed(Conv2D(128, (3,3), activation='relu', padding='same'))(x)\n",
    "x = TimeDistributed(MaxPooling2D())(x)  \n",
    "x = TimeDistributed(Flatten())(x)\n",
    "x = TimeDistributed(Dense(128, activation='relu'))(x)\n",
    "                    \n",
    "x = layers.concatenate([inception_net, x])\n",
    "#x = Flatten()(x)\n",
    "x = Dropout(0.5)(x)\n",
    "x = layers.LSTM(256)(x)\n",
    "#x = Dropout(0.25)(x)\n",
    "x = layers.Dense(nb_classes, activation='softmax')(x)\n",
    "                    \n",
    "model = Model(inputs=[inception_input, yolo_input], outputs=[x])\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "from keras import metrics, callbacks, optimizers\n",
    "from functools import partial\n",
    "\n",
    "top_3_k_categorical_accuracy = partial(metrics.top_k_categorical_accuracy, k=3)\n",
    "top_3_k_categorical_accuracy.__name__ = 'top_3'\n",
    "\n",
    "early_stopper = callbacks.EarlyStopping(patience=5)\n",
    "reduce_lr = callbacks.ReduceLROnPlateau(patience=5, factor=0.75)\n",
    "\n",
    "sgd = optimizers.SGD(momentum=0.9, nesterov=True, lr=0.001)\n",
    "sgd = optimizers.SGD(momentum=0.9, lr=0.001)\n",
    "adam = optimizers.Adam(lr=0.00005)\n",
    "\n",
    "model.compile(optimizer=adam, loss='categorical_crossentropy', \n",
    "              metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_model(**kwargs):\n",
    "    return model.fit_generator(train_generator,\n",
    "                    steps_per_epoch=num_train, \n",
    "                    validation_data=valid_generator,\n",
    "                    validation_steps=num_valid,\n",
    "                    epochs=kwargs.get('epochs', 50))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50\n",
      "70/70 [==============================] - 175s 2s/step - loss: 2.1730 - acc: 0.3054 - val_loss: 1.8494 - val_acc: 0.4741\n",
      "Epoch 2/50\n",
      "70/70 [==============================] - 105s 1s/step - loss: 1.4155 - acc: 0.6920 - val_loss: 1.1325 - val_acc: 0.6961\n",
      "Epoch 3/50\n",
      "70/70 [==============================] - 83s 1s/step - loss: 0.7172 - acc: 0.8652 - val_loss: 0.7230 - val_acc: 0.7759\n",
      "Epoch 4/50\n",
      "70/70 [==============================] - 74s 1s/step - loss: 0.3839 - acc: 0.9268 - val_loss: 0.5421 - val_acc: 0.8017\n",
      "Epoch 5/50\n",
      "70/70 [==============================] - 71s 1s/step - loss: 0.2381 - acc: 0.9536 - val_loss: 0.4741 - val_acc: 0.8405\n",
      "Epoch 6/50\n",
      "70/70 [==============================] - 70s 1s/step - loss: 0.1331 - acc: 0.9848 - val_loss: 0.4394 - val_acc: 0.8621\n",
      "Epoch 7/50\n",
      "70/70 [==============================] - 71s 1s/step - loss: 0.0909 - acc: 0.9866 - val_loss: 0.4572 - val_acc: 0.8405\n",
      "Epoch 8/50\n",
      "70/70 [==============================] - 70s 995ms/step - loss: 0.0591 - acc: 0.9955 - val_loss: 0.4161 - val_acc: 0.8534\n",
      "Epoch 9/50\n",
      "70/70 [==============================] - 73s 1s/step - loss: 0.0351 - acc: 0.9982 - val_loss: 0.4395 - val_acc: 0.8621\n",
      "Epoch 10/50\n",
      "70/70 [==============================] - 69s 992ms/step - loss: 0.0221 - acc: 1.0000 - val_loss: 0.4592 - val_acc: 0.8578\n",
      "Epoch 11/50\n",
      "70/70 [==============================] - 69s 991ms/step - loss: 0.0242 - acc: 0.9982 - val_loss: 0.4524 - val_acc: 0.8642\n",
      "Epoch 12/50\n",
      "70/70 [==============================] - 71s 1s/step - loss: 0.0339 - acc: 0.9946 - val_loss: 0.4921 - val_acc: 0.8642\n",
      "Epoch 13/50\n",
      "70/70 [==============================] - 68s 973ms/step - loss: 0.0278 - acc: 0.9973 - val_loss: 0.4129 - val_acc: 0.8944\n",
      "Epoch 14/50\n",
      "70/70 [==============================] - 72s 1s/step - loss: 0.0092 - acc: 1.0000 - val_loss: 0.4356 - val_acc: 0.8858\n",
      "Epoch 15/50\n",
      "70/70 [==============================] - 69s 991ms/step - loss: 0.0064 - acc: 1.0000 - val_loss: 0.4584 - val_acc: 0.8707\n",
      "Epoch 16/50\n",
      "70/70 [==============================] - 72s 1s/step - loss: 0.0050 - acc: 1.0000 - val_loss: 0.4927 - val_acc: 0.8707\n",
      "Epoch 17/50\n",
      "70/70 [==============================] - 73s 1s/step - loss: 0.0049 - acc: 1.0000 - val_loss: 0.4468 - val_acc: 0.8772\n",
      "Epoch 18/50\n",
      "70/70 [==============================] - 73s 1s/step - loss: 0.0040 - acc: 1.0000 - val_loss: 0.4580 - val_acc: 0.8815\n",
      "Epoch 19/50\n",
      "70/70 [==============================] - 71s 1s/step - loss: 0.0037 - acc: 1.0000 - val_loss: 0.5013 - val_acc: 0.8685\n",
      "Epoch 20/50\n",
      "70/70 [==============================] - 70s 999ms/step - loss: 0.0030 - acc: 1.0000 - val_loss: 0.4530 - val_acc: 0.8836\n",
      "Epoch 21/50\n",
      "70/70 [==============================] - 71s 1s/step - loss: 0.0027 - acc: 1.0000 - val_loss: 0.4962 - val_acc: 0.8750\n",
      "Epoch 22/50\n",
      "70/70 [==============================] - 69s 983ms/step - loss: 0.0023 - acc: 1.0000 - val_loss: 0.4907 - val_acc: 0.8728\n",
      "Epoch 23/50\n",
      "22/70 [========>.....................] - ETA: 13s - loss: 0.0029 - acc: 1.0000"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-8-bf04ed75ab77>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mhistory\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtrain_model\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m<ipython-input-7-68b2e8c2281c>\u001b[0m in \u001b[0;36mtrain_model\u001b[0;34m(**kwargs)\u001b[0m\n\u001b[1;32m      4\u001b[0m                     \u001b[0mvalidation_data\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mvalid_generator\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m                     \u001b[0mvalidation_steps\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mnum_valid\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 6\u001b[0;31m                     epochs=kwargs.get('epochs', 50))\n\u001b[0m",
      "\u001b[0;32m/usr/local/lib/python3.5/dist-packages/keras/legacy/interfaces.py\u001b[0m in \u001b[0;36mwrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     89\u001b[0m                 warnings.warn('Update your `' + object_name +\n\u001b[1;32m     90\u001b[0m                               '` call to the Keras 2 API: ' + signature, stacklevel=2)\n\u001b[0;32m---> 91\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     92\u001b[0m         \u001b[0mwrapper\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_original_function\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     93\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mwrapper\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.5/dist-packages/keras/engine/training.py\u001b[0m in \u001b[0;36mfit_generator\u001b[0;34m(self, generator, steps_per_epoch, epochs, verbose, callbacks, validation_data, validation_steps, class_weight, max_queue_size, workers, use_multiprocessing, shuffle, initial_epoch)\u001b[0m\n\u001b[1;32m   2210\u001b[0m                 \u001b[0mbatch_index\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2211\u001b[0m                 \u001b[0;32mwhile\u001b[0m \u001b[0msteps_done\u001b[0m \u001b[0;34m<\u001b[0m \u001b[0msteps_per_epoch\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2212\u001b[0;31m                     \u001b[0mgenerator_output\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnext\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moutput_generator\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2213\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2214\u001b[0m                     \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mhasattr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mgenerator_output\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'__len__'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.5/dist-packages/keras/utils/data_utils.py\u001b[0m in \u001b[0;36mget\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    771\u001b[0m                     \u001b[0;32mraise\u001b[0m \u001b[0mStopIteration\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    772\u001b[0m                 \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 773\u001b[0;31m                     \u001b[0mtime\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msleep\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwait_time\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    774\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    775\u001b[0m         \u001b[0;31m# Make sure to rethrow the first exception in the queue, if any\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "history = train_model()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sgd = optimizers.SGD(momentum=0.9, lr=0.0005)\n",
    "\n",
    "model.compile(optimizer=sgd, loss='categorical_crossentropy', \n",
    "              metrics=['accuracy', top_3_k_categorical_accuracy])\n",
    "\n",
    "history = model.fit(X_train, Y_train, validation_data=(X_valid, Y_valid), \n",
    "          batch_size=64, epochs=50, callbacks=[reduce_lr])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.set_printoptions(threshold=np.nan)\n",
    "Y_predict = model.predict(X_valid)\n",
    "class_predict = np.argmax(Y_predict, axis=1)\n",
    "print(class_predict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class_true = np.argmax(Y_valid, axis=1)\n",
    "print(class_true)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "for idx in range(len(class_true)):\n",
    "    if class_true[idx] != class_predict[idx]:\n",
    "        print(idx, 'true:', class_true[idx], '  predict:', class_predict[idx], '  prop_true:', Y_predict[idx][class_true[idx]])\n",
    "        print(Y_predict[idx])\n",
    "        print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from count_num_frames_on_dataset import get_number_frames_from_video\n",
    "from inception_generators import get_dataset_split_structure, get_class_to_idx_dict\n",
    "\n",
    "def dataset_loader_with_frames(dataset_dir, split_key):\n",
    "    \n",
    "    base_dir = join(dataset_dir, split_key)\n",
    "    \n",
    "    dataset_structure = get_dataset_split_structure(base_dir)\n",
    "    all_classes = dataset_structure.keys()\n",
    "    class_to_idx_dict = get_class_to_idx_dict(all_classes)\n",
    "        \n",
    "    for cl in all_classes:\n",
    "\n",
    "        class_idx = class_to_idx_dict[cl]\n",
    "\n",
    "        for video in dataset_structure[cl]:\n",
    "            \n",
    "            # ex: video == v_shooting_22_05.npy   or  video == v_walk_dog_10_01.npy\n",
    "            \n",
    "            video_subfolder = video[:video.rfind('_')]\n",
    "            video_mpg = video[:-3] + 'mpg'\n",
    "            \n",
    "            original_video = join('datasets', dataset, 'video', cl, video_subfolder, video_mpg)\n",
    "            number_frames = get_number_frames_from_video(original_video)\n",
    "\n",
    "            inception_features = np.load(join(base_dir, cl, video))\n",
    "\n",
    "            yield inception_features, class_idx, number_frames, video[:-3]\n",
    "                \n",
    "\n",
    "def load_whole_dataset_with_frames(dataset_dir, split_key):\n",
    "        \n",
    "    data = list(dataset_loader_with_frames(dataset_dir, split_key))\n",
    "    X, Y, frames, filenames = map(np.array, zip(*data))\n",
    "\n",
    "    yield X, to_categorical(Y), frames, filenames"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "d = list(load_whole_dataset_with_frames(dataset_dir, 'valid'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_valid_2, Y_valid_2, frames, filenames = zip(*d)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_valid_2, Y_valid_2, frames, filenames = X_valid_2[0], Y_valid_2[0], frames[0], filenames[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Y_predict = model.predict(X_valid_2)\n",
    "class_predict = np.argmax(Y_predict, axis=1)\n",
    "print(class_predict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class_true = np.argmax(Y_valid_2, axis=1)\n",
    "print(class_true)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "frames_incorrect = []\n",
    "class_incorrect = []\n",
    "\n",
    "for idx in range(len(class_true)):\n",
    "    if class_true[idx] != class_predict[idx]:\n",
    "        print(idx, 'true:', class_true[idx], '  predict:', class_predict[idx], '  prop_true:', Y_predict[idx][class_true[idx]])\n",
    "        print('num_frames:', frames[idx], 'filename:', filenames[idx])\n",
    "        print(Y_predict[idx])\n",
    "        print()\n",
    "        frames_incorrect.append(frames[idx])\n",
    "        class_incorrect.append(class_true[idx])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "class_train = np.argmax(Y_train, axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from collections import Counter\n",
    "\n",
    "Counter(class_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "plt.figure(figsize=(10, 6))\n",
    "\n",
    "\n",
    "plt.subplot(121)\n",
    "plt.title('Number of frames inside validation set')\n",
    "plt.hist(frames)\n",
    "\n",
    "\n",
    "plt.subplot(122)\n",
    "plt.title('Number of frames of incorrect predicted validation videos')\n",
    "plt.hist(frames_incorrect)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(10, 6))\n",
    "\n",
    "plt.subplot(121)\n",
    "plt.hist(np.argmax(Y_valid, axis=1))\n",
    "\n",
    "plt.subplot(122)\n",
    "plt.hist(class_incorrect)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.hist(np.argmax(Y_train, axis=1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "d = list(load_whole_dataset_with_frames(dataset_dir, 'train'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_2, Y_train_2, frames_train, filenames_train = zip(*d)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.hist(frames_train[0][frames_train[0] < 600])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "frames_0 = X_train[0]\n",
    "frames_2 = X_train[1]\n",
    "frames_1 = X_train[-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.sum(np.std(frames_0[0:50], axis=0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.sum(np.std(np.concatenate([frames_2[0:25], frames_1[:25]]), axis=0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.sum(np.std(np.concatenate([frames_0[0:25], frames_2[:25]]), axis=0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
